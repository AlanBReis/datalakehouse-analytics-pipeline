# Data Lakehouse com Databricks, Delta Lake e Power BI

Este projeto tem como objetivo demonstrar a criaÃ§Ã£o de uma arquitetura moderna de dados no estilo Lakehouse, utilizando **Databricks**, **Delta Lake**, e **Power BI**. A proposta Ã© simular um pipeline de ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise de dados reais, estruturando um ambiente escalÃ¡vel e voltado para decisÃµes orientadas por dados.

---

## ğŸ” VisÃ£o Geral

A arquitetura do projeto utiliza o conceito de *Data Lakehouse*, que combina a escalabilidade e o custo-benefÃ­cio de um Data Lake com a performance e confiabilidade de um Data Warehouse.

Os dados utilizados no projeto sÃ£o pÃºblicos e simulam um ambiente corporativo com foco em anÃ¡lise exploratÃ³ria e criaÃ§Ã£o de dashboards interativos.

---

## Arquitetura do Projeto

### Diagrama da SoluÃ§Ã£o

![Diagrama do Projeto](./images/estrutura-projeto-datalake.png)

---

## Thumbnail do Projeto

![Thumbnail do Projeto](/images/thumbnail-datalake.png)

---

## Tecnologias Utilizadas

- **Databricks**: plataforma para processamento distribuÃ­do de dados.
- **Delta Lake**: formato de armazenamento transacional otimizado para anÃ¡lise de dados.
- **Apache Spark (PySpark)**: motor de processamento distribuÃ­do para tratamento e transformaÃ§Ã£o de dados.
- **Power BI**: ferramenta de visualizaÃ§Ã£o e exploraÃ§Ã£o dos dados.
- **Azure Data Lake Storage** (opcional): armazenamento de dados brutos.
- **GitHub Actions** (opcional): automaÃ§Ã£o de deploy e versionamento de cÃ³digo.

---

## Estrutura do Projeto

```bash
lakehouse-projeto/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ ingestao_dados.ipynb
â”‚   â”œâ”€â”€ transformacoes.ipynb
â”‚   â””â”€â”€ carga_delta_table.ipynb
â”œâ”€â”€ powerbi/
â”‚   â””â”€â”€ dashboard.pbix
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ diagrama.png
â”‚   â””â”€â”€ thumbnail.png
â””â”€â”€ README.md
```

## Etapas do Projeto

### ğŸ“¥ Coleta e IngestÃ£o dos Dados

- UtilizaÃ§Ã£o de dados pÃºblicos via API ou datasets CSV.
- Armazenamento em formato bruto no Data Lake.

### ğŸ”„ TransformaÃ§Ã£o e OrganizaÃ§Ã£o

- Tratamento dos dados com PySpark.
- Escrita em Delta Lake com versionamento e otimizaÃ§Ãµes.

### ğŸ“Š CriaÃ§Ã£o de Tabelas para Consumo

- Leitura das tabelas Delta.
- OtimizaÃ§Ãµes com `OPTIMIZE`, `ZORDER` e `VACUUM`.

### ğŸ“ˆ VisualizaÃ§Ã£o e AnÃ¡lise

- ConexÃ£o via Power BI.
- CriaÃ§Ã£o de dashboards interativos para anÃ¡lise de KPIs.

---

## Como Rodar o Projeto

### 1. Clone o repositÃ³rio:

```bash
git clone https://github.com/AlanBReis/datalakehouse-analytics-pipeline.git